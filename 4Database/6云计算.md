[[BioInformaticsNote/4Database/README|README]]

# Hadoop

Hadoop：Apache开源组织的一个分布式计算框架，可以在大量廉价的硬件设备组成的集群上运行应用程序，为应用程序提供了一组稳定可靠的接口，旨在构建一个具有高可靠性和良好扩展性的分布式系统
- 来源：
	- 开源项目Lucene：Java开发的开源高性能全文检索工具包
	- 开源项目Nutch：第一个开源的Web搜索引擎
- 组成：Hadoop生态系统
	- HDFS：分布式文件系统，对应 Google GFS
		- 主从结构体系：
			- NameNode：主控制服务器，负责维护文件系统的命名空间（Namespace）并协调客户端对文件的访问，记录命名空间内的任何改动或命名空间本身的属性改动 
			- DataNode：负责它们所在的物理节点上的存储管理
		- 保障可靠性的措施：
			- 冗余备份：每个文件存储成一系列数据块（Block），默认块大小为64MB（可配置）。为了容错，文件的所有数据块都会有副本（副本数量即复制因子，可配置）
			- 副本存放：采用机架感知（Rack-aware）的策略来改进数据的可靠性、可用性和网络带宽的利用率
			- 心跳检测：NameNode周期性地从集群中的每个DataNode接受心跳包和块报告，收到心跳包说明该DataNode工作正常
			- 安全模式：系统启动时，NameNode会进入一个安全模式。此时不会出现数据块的写操作
			- 数据完整性检测：HDFS客户端软件实现了对HDFS文件内容的校验和（Checksum）检查
			- 空间回收：文件被用户或应用程序删除时，先把它移动到/trash目录里；只要还在这个目录里，文件就可以被迅速恢复
			- 元数据磁盘失效：NameNode可以配置为支持维护映像文件和事务日志的多个副本，任何对映像文件或事务日志的修改，都将同步到它们的副本上
			- 快照：快照支持存储某个时间的数据复制，当HDFS数据损坏时，可以回滚到过去一个已知正确的时间点。HDFS目前还不支持快照功能
		- 提升性能的措施：
			- 副本选择：HDFS会尽量使用离程序最近的副本来满足用户请求，这样可以减少总带宽消耗和读延时
			- 负载均衡：HDFS的架构支持数据均衡策略
			- 客户端缓存：HDFS客户端先把数据缓存到本地的一个临时文件，程序的写操作透明地重定向到这个临时文件
			- 流水线复制：DataNode从前一个节点接收数据的同时，即时把数据传给后面的节点，这就是流水线复制
		- 访问接口
			- Hadoop API
				`org.apache.hadoop.conf`
				`org.apache.hadoop.dfs`
				`org.apache.hadoop.fs`
				`org.apache.hadoop.io`
				`org.apache.hadoop.ipc`
				`org.apache.hadoop.mapred`
				`org.apache.hadoop.metrics`
				`org.apache.hadoop.record`
				`org.apache.hadoop.tools`
				`org.apache.hadoop.util`
			- 浏览器接口：典型HDFS安装会配置一个Web服务器开放自己的命名空间，其TCP端口可配；默认配置下`http://namenode-name:50070`这个页面列出了集群里的所有DataNode和集群的基本状态
	- MapReduce：分布式数据处理，对应 Google MapReduce，实现了MapReduce编程框架
		- 任务基本要求：待处理的数据集可以分解成许多小的数据集，而且每一个小数据集都可以完全并行地进行处理
		- 逻辑模型：
			- 映射阶段：用户输入的数据分割为M个片断，对应M个Map任务。每一个Map操作的输入是数据片断中的键值对<K1,V1>集合，Map操作调用用户定义的Map函数，输出一个中间态的键值对<K2,V2> 集合。接着，按照中间态的K2将输出的数据集进行排序，并生成一个新的<K2,list(V2)>元组，按照K2的范围将这些元组分割为R个片断
			- 化简阶段：每一个Reduce操作的输入是一个<K2,list(V2)>片断，Reduce操作调用用户定义的Reduce函数，生成用户需要的键值对<K3,V3>进行输出
		- 实现机制
			- 分布式并行计算
			- 本地计算
			- 任务粒度
			- Combine（连接）
			- Partition（分区）
			- 读取中间结果
			- 任务管道
	- HBase：分布式结构化数据表，对应 Google Bigtable，基于Hadoop Distributed File System，是一个开源的，基于列存储模型的分布式数据库。
		- 简介：一个分布式的、多版本的、面向列的开源数据库
			- 利用Hadoop HDFS作为其文件存储系统，提供高可靠性、高性能、列存储、可伸缩、实时读写的数据库系统
			- 利用Hadoop MapReduce来处理HBase中的海量数据
			- 利用Zookeeper作为协同服务
		- 表的特点：
			- 大：一个表可以有上亿行，上百万列（列多时，插入变慢）
			- 面向列：面向列(族)的存储和权限控制，列(族)独立检索。
			- 稀疏：对于为空(null)的列，并不占用存储空间，因此，表可以设计的非常稀疏。
			- 每个cell中的数据可以有多个版本，默认情况下版本号自动分配，是单元格插入时的时间戳；
			- HBase中的数据都是字符串，没有类型；
		- HBase 特点：
			- 
		- 逻辑模型：
			- 表格里存储一系列的数据行，每行包含一个可排序的行关键字、一个可选的时间戳及一些可能有数据的列（稀疏）
			- 数据行有三种基本类型的定义：行关键字是数据行在表中唯一标识，时间戳是每次数据操作对应关联的时间戳，列定义为：`<family>:<label>（<列族>:<标签>）`
		- 物理模型：物理模型实际上就是把概念模型中的一个行进行分割，并按照列族存储
			- 查询时间戳为t7的“contents:”将返回空值，查询时间戳为t8，“anchor:”值为“look.ca”的项也返回空值（空的单元格不存储）
			- 查询“contents:”而不指明时间戳，将返回t5时刻的数据；查询“anchor:”的“look.ca”而不指明时间戳，将返回t7时刻的数据 （未指明时间戳，则返回指定列的最新数据值 ）
		- 子表服务器
			- 客户端进行更新操作时，首先连接相关的子表服务器，之后向子表提交变更。提交的数据被添加到子表的HMemcache和子表服务器的HLog
			- 提供服务时，子表首先查询缓存HMemcache。若没有，再查找磁盘上的HStore
			- HRegion.flushcache()定期被调用，把HMemcache中的内容写到磁盘上HStore文件里
				- 调用flushcache()方法越少，工作量就越少，而HMemcache就要占用更多的内存空间，启动时HLog文件也需要更多的时间来恢复数据。而调用flushcache()越频繁，HMemcache占用内存就越少，HLog文件恢复数据时也就越快
			- 调用HStore.compact()方法来实现多个HStoreFile合并成一个HStoreFile
			- HRegion.closeAndMerge()可把两个子表合并成一个；HRegion. closeAndSplit()，可将子表分割为两个新子表
		- 主服务器
			- 主服务器维护子表服务器在任何时刻的活跃标记
			- 与Google的Bigtable不同，Bigtable使用分布式锁服务Chubby保证了子表服务器访问子表操作的原子性；HBase不具备这样的Chubby
			- 每个子表都由它所属的表格名字、首关键字和region Id来标识
		- 元数据表：子表的元数据存储在另一个子表里，子表的唯一标识符可以作为子表的行标签，映射子表标识符到物理子表服务器位置的表格称为元数据表
			- 启动时，主服务器立即扫描唯一根子表（其名字是硬编码的）
			- 主服务器扫描元数据子表
			- 主服务器扫描完元数据子表，然后就可以把这些子表分配到子表服务器上去
	- Hadoop Common：Hadoop体系最底层的一个模块，为Hadoop各子项目提供各种工具，如：配置文件和日志操作等。
	- Avro：Avro是doug cutting主持的RPC项目，有点类似Google的protobuf和Facebook的thrift。avro用来做以后hadoop的RPC，使hadoop的RPC模块通信速度更快、数据结构更紧凑。
	- Chukwa：Chukwa是基于Hadoop的大集群监控系统，由yahoo贡献。
	- Hive：hive是基于hadoop分布式计算平台上的提供data warehouse的sql功能的一套软件。使得存储在hadoop里面的海量数据的汇总，即席查询简单化。hive提供了一套QL的查询语言，以sql为基础，使用起来很方便。
	- Pig：对应 Google Sawzall，Pig是SQL-like语言，是在MapReduce上构建的一种高级查询语言，把一些运算编译进MapReduce模型的Map和Reduce中，并且用户可以定义自己的功能。
	- ZooKeeper：对应 Google Chubby，它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。






