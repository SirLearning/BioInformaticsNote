# 计算机网络
#### 1. OSI七层模型 与 Tcp/Ip 分层模型
```
    应用层           应用层
                    表示层
                    会话层
	---------------------
    传输层           传输层
	---------------------
    网络层           网络层
    ---------------------
    网络接口层        数据链路层
                    物理层
	---------------------
    tcp/ip 模型     osi 七层模型
```

#### 2. `epoll` 和 `select` 的区别  
`select` 存在的主要问题：

+ `select`最大可监视的文件描述符数量是 1024。尽管可以修改，因为`select`采用的轮询的方式，文件描述符数目越大，性能越差。
+ 调用 `select`时，每次都需要将整个数组复从用户空间复制到内核空间，数据拷贝具有一定的开销。
+ `select` 返回的是含有所有文件描述符的数组，用户需要遍历整个数组才能发现哪些 `socket`产生了事件。

`epoll` 高效的原因

`select`主要问题是2和3，`epoll`对此改善。`epoll` 通过在 `linux` 内核中申请一个简易的文件系统（文件系统一般用什么数据结构实现？B+树），将 原来的 `select/poll`函数调用过程分为3个部分：

+ 调用 `epoll_create()` 建立一个epoll对象（在epoll文件系统中为这个句柄对象分配资源）
+ 调用 `epoll_ctl()` 向 `epoll` 对象中添加 `socket` 关注的事件
+ 调用 `epoll_wait` 收集发生的事件的 `socket` 

**过程**  
调用 `epoll_create`时，`Linux` 内核会创建一个 `strcut eventpoll`对象，就是`epollfd`对应的主要数据结构。
```cpp
struct eventpoll{
    spin_lock_t       lock;         // 对本数据结构的访问 
    struct mutex      mtx;          // 防止使用时被删除 
    wait_queue_head_t wq;           // sys_epoll_wait()使用的等待队列 
    wait_queue_head_t poll_wait;    // file->poll()使用的等待队列 
    struct list_head  rdllist;      // 事件满足条件的链表 ：双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件
    struct rb_root    rbr;          // 用于管理所有fd的红黑树：红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件
    struct epitem*    ovflist;      // 将事件到达的fd进行链接起来发送至用户空间
};
```
这个结构体用于存放每次调用 `epoll_ctl` 时添加的事件，即存放注册的一些事件。这些事件都会存在红黑树 `rbr` 上。在添加重复的事件时，可以快速地找到。而所有添加 `epoll` 对象中事件都会与网卡驱动程序建立回调关系`ep_poll_callback`：将发生的事件添加到就绪列表 `rdlist` 中去。

在`epoll`中，每个事件都会创建 `struct epitem`对象： 
```cpp
struct epitem{
    struct rb_node      rbn;        // 红黑树节点
    struct list_head    rdllink;    // 双向链表节点
    struct epoll_filefd ffd;        // 事件句柄信息
    struct eventpoll*   ep;         // 指向其所属的eventpoll对象
    struct epoll_event  event;      // 期待发生的事件类型
};
```
下图的左上角文字写错了，应该是：双向链表中的每个节点都是基于 `epitem` 中的 `rdllist`成员。

  <div align=center> <img  width =450 height=350 src = ./Image/epoll_.png> </div>

调用 `epoll_wait` 时，不用传递 `socket`文件描述符给内核，这是因为 内核已经在调用 `epoll_ctl` 时就已经获得需要监视的 `socket`。将注册事件和堵塞等待分开。如果此时 `rdlist` 有数据成员，说明有就绪事件，那么可以直接返回。否则就阻塞等待，超时返回。

**高效的原因** 

`epoll` 在被内核初始化时会开辟出 `epoll` 自己的内核高速 `cache` 区用于安置每一个我们想监控的 `socket`，这些 `socket` 会以红黑树的形式保存在内核 `cache`里，以支持快速的查找、插入、删除。

这是由于我们在调用 `epoll_create` 时，内核完成了三件事：
+ 在 `epoll`文件系统里建了个`file`结点，这个文件只是服务于 `epoll`。
+ 在内核 `cache` 里建了个红黑树用于存储每次调用 `epoll_ctl` 传来的 `socket`。
+ 建立一个 `rdlist` 链表，用于存储准备就绪的事件。

当 `epoll_wait` 调用时，仅仅观察 `eventpoll` 对象的双链表 `rdlist`有没有数据即可。有数据就将发生的事件复制到用户态度同时将事件数量返回给用户，没有数据就阻塞，直到 `timeout`时间到后即使链表没数据也返回。

需要注意，select. poll, epoll本身都是阻塞的同步IO模式。

[参考连接](https://www.zhihu.com/search?type=content&q=epoll)

#### 3. LINUX 同步IO/异步IO 区别    
同步IO向应用程序通知的是 **“IO就绪事件”**，而异步IO向应用程序通知的是 **“IO完成事件”**：
+ 同步：同步IO模型是需要自己执行IO操作，比如将数据从内核缓冲区读取到用户缓冲区，或者将数据从用户缓冲区写入到内核缓冲区。
+ 异步：异步IO机制则是由内核来执行IO操作，数据在内核和用户态之间的移动是由内核在后台完成的。

#### 4. `Reactor`和`Proactor`区别  

+ Reactor 模式  

  `Reactor` 是这样一种模式，它要求主线程只负责监听文件描述上 是否有事件发生，有的话就立即将该事件通知工作线程。除此之外，主线程不做任何其他实质性的工作。读写数据，接受新的连接，以及处理客户诮求均在工作线 程中完成。

  <div align=center> <img src=./image/reactor.jpg> </div>

+ proactor 

  与Reactor模式不同，Proactor模式将所有 I/O 操作都交给主线程和内核来处理，工作线程仅仅负责业务逻辑。

#### 5. 高效的并发模式-半同步半异步模型

此处的同步与前面的IO模式中的同步不是一个概念。
+ 在IO模型中的，同步与异步区分的是内核向应用程序通知的是何种IO事件（是就绪事件还是完成事件），以及该谁来完成IO读写（是应用程序还是内核）。
+ 在并发模式中，“同步”指的是程序完全按照代码序列的顺序执行：“异步” 指的是程序的执行需要由系统事件来驱动。常见的系统事件包括中断、信号等。

<div align=center><img src=./image/并发设计模式.jpg> </div>

**半同步/半异步**  
半同步/半异步模式结合了同步的简单与异步的效率。

半同步/半异步模式中，同步线程用于处理客户逻辑（工作线程）；异步线程用于处理 `I/O` 事件（主线程）。异步线程监听到客户诸求后，就将其封装成请求对象并插入诸求队列中。
诮求队列将通知某个工作在同步模式的工作线程来读取并处理该请求对象。

在服务器程序中， 如果结合考虑两种串件处理模式和几种l/0模烈， 则半同步/半异步模式就存在多种变体。其中有一种变体称为半同步/半反应堆(half-sync/half-reactive) 模式。如图

<div align=center><img src=./image/半同步半异步模式.jpg> </div>

异步线程只有一个， 由主线程来充当。它负责监听所有socket 上的事件。
+ 如果监听socket 上有可读事件发生， 即有新的连接请求到来，主线程就接受之以得到新的连接socket, 然后往epoll 内核事件表中注册该 连接socket 上的读写事件。
+ 如果连接socket 上有读写事件发生， 即有新的客户请求到来或有数据要发送至客户端， 主线程就将该连接socket 插人请求队列中。所有工作线程都睡眠在请求队列上， 当有任务到来时， 它们将通过竞争（比如申诸互斥锁）获得任务的接管权。这种竞争机制使得只有空闲的工作线程才有机会来处理新任务， 这是很合理的。

但是这个模式仍然具有较多的缺点

因此诞生了更为高效的半同步/半反应堆模式，也是`muduo`采用的设计模式。

<div align=center><img src=./image/半同步半反应堆模式改进.jpg> </div>

主线程只管理监听`socket`, 连接`socket`由工作线程来管理。 当有新的连接到来时， 主线程就接受之并将新返回的连接socket派发给某个工作线程， 此后该新的连接socket上的任何 I/O 操作都由被选中的工作线程来处理， 直到客户关闭连接。

每个线程（主线程和工作线程）都维持自己的事件循环，它们各自独立地监听不同的事件。 因此，在这种商效的半同步/半异步模式中， 每个线程都工作在异步模式， 所以它并非严格意义上的半同步/半异步校式。

#### 6. ARP原理

`ARP` 完成的是从`ip` 地址到硬件地址的映射。

+ 每个主机都会在自己的 `ARP` 缓冲区中建立一个 `ARP` 列表，以表示`IP`地址和 `MAC`地址之间的对应关系。 
+ 当源主机要发送数据时，首先检查 `ARP` 列表中是否有对应 `IP` 地址的目的主机的 `MAC` 地址。如果有则直接发送数据，如果没有就向本网段的所有主机发送ARP数据包，该数据包包括的内容有：源主机IP地址，源主机`MAC`地址，目的主机的 `IP` 地址。 
+ 当本网络的所有主机收到该ARP数据包时，首先检查数据包中的`IP`地址是否是自己的`IP`地址，如果不是则忽略该数据包，如果是，则首先从数据包中取出源主机的`IP`和`MAC`地址写入到`ARP`列表中，如果已经存在，则覆盖，然后将自己的MAC地址写入ARP响应包中，告诉源主机自己是它想要找的MAC地址。 
+ 源主机收到ARP响应包后。将目的主机的IP和MAC地址写入ARP列表，并利用此信息发送数据。如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。

#### 7. RARP原理

RARP是逆地址解析协议，作用是完成硬件地址到IP地址的映射，主要用于无盘工作站，因为给无盘工作站配置的IP地址不能保存。 

工作流程：在网络中配置一台RARP服务器，里面保存着IP地址和MAC地址的映射关系，当无盘工作站启动后，就封装一个RARP数据包，里面有其MAC地址，然后广播到网络上去，当服务器收到请求包后，就查找对应的MAC地址的IP地址装入响应报文中发回给请求者。因为需要广播请求报文，因此RARP只能用于具有广播能力的网络。


### 8. 在地址栏输入url之后发生什么
+ 浏览器会根据输入的url中的域名通过dns服务器解析出域名对应的ip地址.
  
  + dns解析：
    + 首先客户端根据你输入的域名去浏览器dns缓存中查找是否有对应的ip，
    + 如果没有，则会去寻找本地的hosts文件(windows系统dns缓存)，检查文件中是否有域名和IP的对应关系。
    + 如果有，则根据这个IP地址建立连接。如果没有，再去DNS服务器寻找。
  
  +  dns 解析函数：`getaddrinfo`
+ 浏览器获得服务器的ip地址后，就会尝试与服务器进行三次握手建立TCP连接
+ 建立连接后，浏览器将地址栏的url封装成Htttp请求，发送给服务器，服务器根据客户端的处理逻辑做出相应的响应，服务器将获得的处理结果封装成Http回应帧，发送给浏览器
+ 浏览器展示内容

### 9. ping 原理

使用的是 ICMP 协议

