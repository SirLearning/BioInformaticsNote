# Linux
## 内存映射
### 页表

物理内存即 **DRAM**
### 页 
在任意时刻，虚拟页面的集合都分为三个不相交的子集：
+ 未分配的：虚拟系统还未分配（或者创建）的页。 未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间。
+ 缓存的 ： 当前已缓存在物理内存中的已分配页。
+ 未缓存的：未缓存在物理内存中的已分配页
### 页表
页表是存储在物理内存中，功能是将虚拟页映射到物理页。每次地址翻译硬件将一个虚拟地址转换为物理地址时，都会读取页表。操作系统会维护页表的页表的内容，以及在磁盘和DRAM之间来回传送页。

页表是常驻在物理内存中，页表本质上可以当作数组来看待，每个元素（即，页表条目）是由“有效位+地址”组成。有效位指示该虚拟页是否被缓存在DRAM中：如果设置了有效位，那么地址字段就表示 `DRAM` 中相应的物理页的起始地址。如果没有设置有效位，而地址段是一个空的地址，表示这个虚拟页还未被分配；如果不是空的地址，那么表示的这个虚拟页在磁盘中的起始位置，后面发生缺页中断时，进行页面置换算法将这个虚拟页从磁盘调入进内存中。

如下图显示：

  <div align=center> <img src=./image/页表_1.jpg> </div>

### 页命中与缺页中断

当CPU**访问**包含在VP2中的虚拟内存的一个变量时，vp2将会被缓存在DRAM中。通过某个机制找到该变量的虚拟地址，地址翻译硬件将虚拟地址作为一个索引来定位PTE2，并从虚拟内存中读取他。因为设置了PTE2的有效位，那么地址翻译单元就知道VP2是已经缓冲在内存中，就是可以使用PTE2中的物理内存地址，构造出这个变量的物理地址。

  <div align=center> <img src=./image/页表_2.jpg> </div>

如果我门要访问的变量在vp3中，但是vp3没有被缓存在 `DRAM` 中，虚拟内存中将DRAM缓存不命中称为缺页。

地址翻译单元从内存中读取PTE3，从有效位推断出VP 3未被缓存，并且触发一个缺页异常。 缺页异常调用内核中的缺页异常处理程序，该程序会选择一个牺牲页， 在此例中就是存放在pp3处的VP4。 如果VP4 已经被修改了， 那么内核就会将它复制回磁盘。 无论哪种情况，内核都会修改VP4的页表条目，反映出VP4不再缓存在主存中这一事实。

  <div align=center> <img src=./image/页表_3.jpg> </div>

接下来， 内核从**磁盘**复制VP3到内存中的pp3, 更新PTE3, 随后返回。 当异常处理程序返回时， **它会重新启动导致缺页的指令**，该指令会把导致缺页的虚拟地址重发送到地址翻译硬件。 现在VP3已经缓存在主存中了， 那么页命中也能由地址翻译硬件正常处理了。 图9-7展示了在缺页之后我们的示例页表的状态。

  <div align=center> <img src=./image/页表_4.jpg> </div>

### 分配页

下图展示了当操作系统分配一个新的虚拟页时对我们上述示例页表的影响。比如，调用 `malloc` 的结果，在这个示例中，`vp5`的分配过程是在磁盘上创建空间，并更新PTE5，使她指向磁盘上这个新创建的页面。

<div align=center><img src=./image/页表_5.jpg></div>

### 多级页表

之所以需要存在多级页面。根据局部性原理可知，进程在一段时间内，只需要访问某几个页面就能正常运行。因此没有必要将整个物理内存的页表都加载进来，实现方式就是缺页中断实现数据交换。
## 虚拟内存
虚拟内存为每个进程提供了一个大的、独立的、一致的地址空间。  
+ 在主存中只保存活动区域，在磁盘和主存之间通过缺页中断来回传送数据， 高效地使用了主存，等效地扩大了内存空间 
+ 它为每个进程提供了一致的地址空间， 从而简化了内存管理
+ 它保护了每个进程的地址空间不被其他进程破坏
### 虚拟地址空间

  <div align=center> <img width=400 height=500 src=./image/进程地址空间.jpg> </div>

+ 物理地址空间与虚拟地址空间的区别

  大小
  + 物理地址空间的大小是由地址总线决定的：比如32位系统，物理地址空间：$4G = 2^{32}$。
  + 进程的虚拟地址空间是物理地址空间大小相同。比如32位系统，他的进程虚拟空间大小就是 $4G$

  寻址方式不同
  + 物理地址空间的地址是可以直接寻址内存
  + 虚拟地址空间的地址需要经过内存管理单元`MMU（memory manger unit）` 翻译得物理地址，再去寻址内存

+ 什么时候发生虚拟内存向物理内存的映射

  初始化的时候会建立一部分映射
  ```cp
    #include <iostream>
  
    int main(int argc, char const *argv[])
    {
      int a =10;
      int b =1;
  
      std::cout<<(a + b)<<std::endl;
      return 0;
    }
  ```
  对于上述代码，编译会得到的信息如下：
  ```cpp
    $ g++ -static main.cc -o main.elf && readelf -l main.elf 
  
    Elf 文件类型为 EXEC (可执行文件)
    Entry point 0x404b00
    There are 10 program headers, starting at offset 64
  
    程序头：
      Type           Offset             VirtAddr           PhysAddr
                    FileSiz            MemSiz              Flags  Align
      LOAD          0x0000000000000000 0x0000000000400000 0x0000000000400000
                    0x00000000000005f0 0x00000000000005f0  R      0x1000
      LOAD          0x0000000000001000 0x0000000000401000 0x0000000000401000
                    0x000000000017185d 0x000000000017185d  R E    0x1000
      LOAD          0x0000000000173000 0x0000000000573000 0x0000000000573000
                    0x00000000000533f9 0x00000000000533f9  R      0x1000
      LOAD          0x00000000001c6940 0x00000000005c7940 0x00000000005c7940
                    0x000000000000bc10 0x0000000000010268  RW     0x1000
      NOTE          0x0000000000000270 0x0000000000400270 0x0000000000400270
                    0x0000000000000020 0x0000000000000020  R      0x8
      NOTE          0x0000000000000290 0x0000000000400290 0x0000000000400290
                    0x0000000000000044 0x0000000000000044  R      0x4
      TLS           0x00000000001c6940 0x00000000005c7940 0x00000000005c7940
                    0x0000000000000068 0x00000000000000b8  R      0x8
      GNU_PROPERTY  0x0000000000000270 0x0000000000400270 0x0000000000400270
                    0x0000000000000020 0x0000000000000020  R      0x8
      GNU_STACK     0x0000000000000000 0x0000000000000000 0x0000000000000000
                    0x0000000000000000 0x0000000000000000  RW     0x10
      GNU_RELRO     0x00000000001c6940 0x00000000005c7940 0x00000000005c7940
                    0x00000000000096c0 0x00000000000096c0  R      0x1
  ```

  对程序中的变量进行读写时，发生缺页中断会建立映射
## Linux 进程间通信方式
*Linux* 进程间通讯方式有：管道，信号，消息队列，共享内存，套接字共六种。[参考地址](https://www.zhihu.com/question/23995948/answer/136236554)

#### 管道 

分为有名管道（PIPE）和无名管道（FIFO）。管道都是半双工的，数据只能单向流动。PIPE和FIFO用来实现进程间相互发送非常短小的、频率很高的消息；**这两种方式通常适用于两个进程间的通信。**

+ 无名管道：只能在具有亲缘关系的进程间使用，利用的是 fork 函数调用之后的两个管道文件描述符 `fd[0]`, fd[1]都保持打开，一对这样的文件描述符只能保证父、子进程间的一个方向的数据传输，父子进程必须有一个关闭 `fd[0]`，另一个关闭 `fd[1]`

  <div align=center><img src=./image/pipe_1.jpg> </div>

  如果要实现双向管道传输，必须使用两个管道。  
  ```c
    int pipe(int fd[2]);
  ```
  + `fd[0]`：读
  + `fd[1]`：写

+ 有名管道：它允许无亲缘关系进程间的通信。
#### 信号   
信号是一种比较复杂的通信方式，信号产生的条件：按键、硬件异常、进程调用kill函数将信号发送给另一个进程、用户调用*kill*命令将信号发送给其他进程，传递的消息比较少用于通知接收进程某个时间已经发生。

不能跨局域网，而且信息量少。

#### 消息队列  
消息队列是消息的链表，存放在内核中并由消息队列标识符标识，消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点。  不建议使用，现在很多成熟的消息队列。
#### 共享内存     
共享存储是最高效的IPC机制，因为不涉及进程之间的任何数据传输，但是必须辅助其他方式（比如信号量）来同步进程对共享内存的访问，否则会产生竞态条件(*race condition*)。共享内存适合实现进程间共享的、非常庞大的、读写操作频率很高的数据（配合信号量使用）；**这种方式通常适用于多进程间通信** 。无须复制，快捷、信息量大是其优点。

#### 套接字 *socket*  
套接字可用于不同及其间的进程通信。可以跨局域网适应分布式的需求。首选socket来实现进程间通信。

## 常见信号

显示所有的信号：`kill -l`

|signum| 信号     | 处理方式   | 来源	  							|
| :--: | :----:  | :-------: | :---------------------------------:|
| 2    | SIGINT  | terminate | 来自键盘中断 ctr+C 					 |
| 6	   | SIGABRT | terminate | assert 触发						 |
| 11   | SIGSEGV | dump		 | 无效的内存引用						  |
| 14   | SIGALRM | terminate | 定时器信号						    |
| 9    | SIGKILL | terminate | 强迫进程终止 kill-9					|
| 15   | SIGTERM | terminate | 进程终止（不带参数时Kill 默认发送的信号）  |
| 19   | SIGSTOP | stop		 | 停止进程执行						 |
| 13 | SIGPIPE | terminate | 向已经关闭的管道写数据				  |
| 17 | SIGCHLD | SIG_IGN   | 子进程死亡							  |





