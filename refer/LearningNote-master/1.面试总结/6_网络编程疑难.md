# 网络编程疑难
### 工具使用
+ `telnet ip port`   
  可以检测是服务器开发还是服务器的问题。先`ping`一下说明网络是没问题的。再telent一下
    + 连的上的服务端问题
    + 连不上是客户端问题

### Socket 函数
+ `bind` 端口号不指定，
  操作系统自己选择一个，
  
  应用场景：唤醒服务

  网络库不能依赖很多特性，因此此时操作系统自己选择一个端口号很方便，实现linux下的唤醒机制。

  客户端也是可以用在客户端，将某个sockfd 绑定到指定的地址和端口号来连接服务端，

#### Socket 函数的非阻塞行为

##### 1. 读取：`read`,` recv`, `readv `   

对于非阻塞套接字，在非阻塞下的行为，根据返回值 `n` 可以有几种行为：

  + `n >0`：成功读取数据，`n`读取到的字节数
  + `n =0`: 表示对端关闭    

为什么不可能接受到0字节的数据 ?

```
接收到0字节的数据，意味着对端要发送个0字节的数据的。但是一个能在数据链路上发送的最小IP数据包大小是46字节：IP头部一般是20字节，TCP头部一般是20字节，如果应用层数据是0字节，整个IP数据包大小40字节小于46字节，根本无法发送出去，因此接收端不可能接收到大小为0字节的数据包。
```

<div align=center> <img src=./image/以太网数据帧_1.jpg></div>

  + n < 0：在非阻塞模式下要根据错误码判断是不是真的发生错误。
    + **`EAGAIN/EWOULDBLOCK`**：当前缓冲中没有数据可读，不是真的错误，**需要再次调用这个函数进行重试**
    + **`EINTR`**：被信号中断，不是真的错误，**需要再次调用这个函数进行重试**
    + 其他：是真的错误，需要关闭连接

##### 2. 写操作： `write`,` send`, `writev`  

在非阻塞套模式下，行为大致和 `read` 操作返回值含义一致。如果其发送缓冲区中已经没有空间，输出调用将立即返回错误：`EWOULDBLOCK`。如果发送缓冲区中还有一些空间，返回值就是复制到内核的字节数。

`write` 不存在返回0，因为如果返回0，就是表示发送缓冲区已满，不可再将数据复制到发送缓冲区，此时就是返回-1 且 `erron = EAGAIN/EWOULDBLOCK`。

##### 3. 接受外来连接：`accept`

对于一个非阻塞套接字使用 `accept`，也是返回 `EWOULDBLOCK`。不过这个操作一般是阻塞的，因为已经有 `epoll/select`存在代替这个函数阻塞。

##### 4. 发起连接：`connect`

TCP连接建立涉及三次握手，客户端要一直等接收到服务对于自己的`SYN`请求的`ACK`应答，`connect`才是会返回，即第二次握手成功，`connect`才返回，因此每个TCP的 `connect` 调用都至少阻塞一个 RTT的时间。

对于一个非阻塞套接字调用`connect`，并且连接不能立即建立，那么连接照样能发起，不过会返回一个 **`EINPROGRESS`** 错误。 稍后可以使用 `select` 是否可读可写来判断是否建立成功：

  + 在 Windows 系统上，一个 socket 没有建立连接之前，我们使用 select 函数检测其是否可写，能得到正确的结果（不可写），连接成功后检测，会变为可写。所以，上述介绍的异步 connect 写法流程在 Windows 系统上是没有问题的。

  + 在 Linux 系统上一个 socket 没有建立连接之前，用 select 函数检测其是否可写，你也会得到可写的结果，所以上述流程并不适用于 Linux 系统。正确的做法是，connect 之后，不仅要用 select 检测可写，还要检测此时 socket 是否出错，通过错误码来检测确定是否连接上，错误码为 0 表示连接上，反之为未连接上。完整代码如下

#### 域名解析   

使用域名的好处在于可以避免服务前当前使用的 `ip:port`崩溃了，可以使用切换到其他 `ip：port`，而不至于服务停止。对于客户端而言没有影响，这个可以使用 `ifconfig` 来判断。

+ `getaddrinfo`：域名与ip的转换


### 设计网络库，需要考虑的功能

####  1. 使用哪种io复用函数 
**select 函数**

+ `select `常常用户客户端的使用

**epoll 函数** 

+ `epoll_create` 的参数任意正数
+ 读写+LT/ET 共四种工作方式
  + et模式的读和写两个方面考虑，读可能会造成数据积压

#### 2. 事件触发   

+ `EPOLLIN`
    + 内核中Socket接受缓冲区为空  -->  低电平 --> 不可读
    + 内核中Socket接受缓冲区不空  -->  高电平 --> 可读
+ `EPOLLOUT`
    + 内核中Socket发送缓冲区为满  -->  低电平 --> 不可写
    + 内核中Socket发送缓冲区不满  -->  高电平 --> 可写

工作模式

+ `LT`电平触发：高电平触发
+ `ET`边缘触发：
    + 低电平-->高电平 触发
    + 高电平-->低电平 触发  

#### 3. 收发数据的正确姿势

对于收发数据，对于每个*TcpConnection* 对象都需要一个接受/发送的缓冲区。接受/发送数据的逻辑截然不同
+ 接受数据： `read`、`recv` 
  
    在`accept`之后直接注册可读事件，在可读事件的回调函数中实现数据的读取  
    
+ 发送数据：`write`、`send`    

##### LT 模式

在  `connfd = accept(listenfd,...)` 获得监听套接字`connfd`之后，不能立即监听`connfd`的`EPOLLOUT`事件，因为刚获得`connfd`的接受缓冲区肯定是空的，一直处于高电平，处于可写状态。如果此时就监听那么将一直触发`epoll_wait`函数，会一直等待写，消费CPU资源。这个现象即`busy loop`。 正确的流程 : 

 在第一次你 *`n=write(connfd, buffer, sizeof(BUFFER))`* 之后，根据函数返回值`n`有两种情况：
  + `n == sizeof(buffer)`
    
     即已将应用层 `OutBuffer` 的数据全部发送数据了，那么只是需要等待下次用户发送数据
     
  + `n==-1 && erron = EWOULDBLOCK/EAGAIN`.  
   
    这个是 `socket`的发送缓冲区已经满了，无法再发送数据。因此非阻塞模式下的`write/send` 会立即返回-1，并且将错误码`erron` 设置为 `EWOULDBLOCK/EAGAIN`，此时需要做两件事： 
      1. 需要将未发完的数据添加到应用层缓冲区 `OutBuffer`
      2. **关注 `connfd` 的 `EPOLLOUT` 事件**     

    然后等待 `connfd` 的 `EPOLLOUT` 事件的到来：取出应用层的缓冲区中的数据继续发送 *`write(connfd, ...)`* 。如果应用层缓冲区中的数据发送完毕，**取消关注`EPOLLOUT`事件**。因为不取消，`sokcet` 发送缓冲区为空后，又会触发`EPOLLOUT`，但是此时数据已经发送完毕，又会陷入`busy loop。`

    

   **[应用层的流量控制]**：如果对端出现故障或者什么原因，导致对端一直不接受数据，而发送端还是一直发送数据，会导致 `outBuffer_`超过一定阈值，就是可以切除这个连接。或者其他处理。

  + `n==-1`：如果此时错误码不等于上述的和 `EINTR` ，那么就对端可能已经崩溃，需要直接关闭连接 

     

 **muduo LT模式下发送数据源码展示** 

  ```cpp
  void TcpConnection::sendInLoop(const void* data, size_t len) {
    loop_->assertInLoopThread();
    ssize_t nwrote   = 0;
    size_t remaining = len;
    bool faultError  = false;
    if (state_ == kDisconnected)
    {
      LOG_WARN << "disconnected, give up writing";
      return;
    }

    /// 如果没有关注可写事件 且 @b outputBuffer_ 中无待发送数据，说明之前的数据都已经写完
    /// 对于 用户来说是向 @b outputBuffer_ 中写，
    /// 对于 @c socket 来说是从  @b outputBuffer_ 中读取
    /// if no thing in output queue, try writing directly
    if (!channel_->isWriting() && outputBuffer_.readableBytes() == 0)
    {
      nwrote = sockets::write(channel_->fd(), data, len);
      if (nwrote >= 0)
      {
        remaining = len - nwrote;
        // 全部写完了，那么就执行写完成回调
        if (remaining == 0 && writeCompleteCallback_)
        {
          loop_->queueInLoop(std::bind(writeCompleteCallback_, shared_from_this()));
        }
      }
      else // nwrote < 0
      {
        nwrote = 0;
        /// socket 的发送缓冲已经满，无法将 outputBuffer_ 的数据都复制到 socket 的发送缓冲区
        /// 非阻塞模式下，函数返回 -1,errno == EWOULDBLOCK
        /// 如果错误码不是EWOULDBLOCK，那么是真的产生错误了，需要关闭连接
        if (errno != EWOULDBLOCK) 
        {
          LOG_SYSERR << "TcpConnection::sendInLoop";
          if (errno == EPIPE || errno == ECONNRESET) // FIXME: any others?
          {
            faultError = true;
          }
        }
      }
    }

    assert(remaining <= len);
    /// @brief: 运行到这有两种可能：
    /// 1 之前没有注册可写事件，且 @b outputBuffer_ 中没有可读取数据，
    /// 	运行到此是因为此次数据 data 没有发送完
    /// 2 之前的数据没有发送完，又来了新的数据
    /// 无论哪种情况，处理方式：
    ///  将数据复制到  @b outputBuffer_ 中，关注 @b EPOLLOUT 事件，等待可写事件触发，发送数据
    if (!faultError && remaining > 0)
    {
      size_t oldLen = outputBuffer_.readableBytes();
      // 待发送的内容已经超过标志位了，就调用高水位这个函数
      if (oldLen + remaining >= highWaterMark_  &&
          oldLen < highWaterMark_  &&
          highWaterMarkCallback_)
      {
        loop_->queueInLoop(std::bind(highWaterMarkCallback_, 
                                     shared_from_this(), 
                                     oldLen + remaining));
      }
      /// 将剩余的内容加如 @b outbuffer_
      outputBuffer_.append(static_cast<const char*>(data)+nwrote, remaining);

      /// 在LT 模式下不需要重复关注可写事件，即使运行到此的第二种情况不需要再关注可写事件
      if (!channel_->isWriting())
      {
        channel_->enableWriting();
      }
    }
  }

  /// @brief: 写回调函数
  void TcpConnection::handleWrite()
  {
    loop_->assertInLoopThread();
    /// 触发写回调函数
    /// 将 @b outputBuffer_ 中的数据复制到 @b socket 的发送缓冲区
    if (channel_->isWriting())
    {
      ssize_t n = sockets::write(channel_->fd(),
                                 outputBuffer_.peek(),
                                 outputBuffer_.readableBytes());
      if (n > 0)
      {
        outputBuffer_.retrieve(n);
        /// 如果 @b outputBuffer_ 中的数据全部写完，
        /// 那么就可以取消关注 @b EPOLLOUT ，防止出现 busy loop
        /// 并且调用写完成回调函数
        /// 如果全部写完，此时就需要取消关注可写事件
        /// 如果 @b outbuffer_ 中还有数据，就继续等待下次可写事件的触发
        if (outputBuffer_.readableBytes() == 0)
        {
          channel_->disableWriting();
          if (writeCompleteCallback_)
          {
            loop_->queueInLoop(std::bind(writeCompleteCallback_, shared_from_this()));
          }
          if (state_ == kDisconnecting)
          {
            shutdownInLoop();
          }
        }
      }
      else
      {
        LOG_SYSERR << "TcpConnection::handleWrite";
        // if (state_ == kDisconnecting)
        // {
        //   shutdownInLoop();
        // }
      }
    }
    else
    {
      LOG_TRACE << "Connection fd = " << channel_->fd()
                << " is down, no more writing";
    }
  }    
  ```
流程展示：    
  <div align=center> <img wdith=350 height =300 src=./image/epoll_LT.jpg> </div>

##### ET模式

在ET模式下正确的流程：在 `connfd = accept(listenfd,...)` 之后就可以关注`connfd`的可读/可写事件，在触发可读/可写事件之后

   + 读操作要一直到读到函数 `read` 返回 `EAGAIN` 

     触发 `EPOLLIN` 事件后，如果 `connfd` 的接受缓冲区中的数据没有读取完毕，那么当  `connfd`  的又接受到新的缓冲区数据时，`EPOLLIN`事件不会触发。因为之前的数据没有读取完，处于高电平状态，此时又来新的数据并没有改变电平状态，因此即使有新的数据到来也无法触发 `EPOLLIN`。此时就会导致严重的丢包、数据混乱问题。

   + 写操作要一直写到发送缓冲区`outBuffer_`为空，或者函数返回`EAGAIN`

     上面的 `epoll LT` 模式注册一次监听可写事件后，可写事件触发后，尝试发送`outBuffer_`中的剩余数据，如果数据此时还不能全部发送完，不用再次注册可写事件。
           
     如果是 `epoll ET` 模式，注册监听可写事件后，可写事件触发后，尝试发送数据，如果数据此时还不能全部发送完，**需要再次注册可写事件以便让可写事件下次再次触发（给予再次发数据的机会）**。
           

    当然，这只是理论上的情况，实际开发中，如果一段数据反复发送都不能完全发送完（例如对端先不收，后面每隔很长时间再收一个字节），我们可以设置一个最大发送次数或最大发送总时间，超过这些限定，我们可以认为对端出了问题，应该立即清空发送缓冲区并关闭连接

  流程展示 

      <div align=center> <img wdith=350 height =300 src=./image/epoll_ET.jpg> </div>

**[面试题]**：阻塞型和非阻塞型文件描述符，都能用epoll的LT和ET模式吗？    

    阻塞模式下不能用 ET，非阻塞下都可以。

 ET模式下每次 `write` 或 `read` 需要循环 `write` 或 `read` 直到返回 `EAGAIN` 错误。以读操作为例，这是因为ET模式只在 `socket` 描述符状态发生变化时才触发事件，如果不一次把 `socket` 内核缓冲区的数据读完，会导致`socket` 内核缓冲区中即使还有一部分数据，该 `socket` 的可读事件也不会被触发。

 根据上面的讨论，若ET模式下使用阻塞IO，则程序一定会阻塞在最后一次`write/read`操作，因此说`ET`模式下一定要使用非阻塞IO。

**[面试题]：**为什么要设计个 Buffer 类

    对于读事件：一次性scoket数据全部读取到 `inputBuffer_`，避免一直触发 `epoll_wait`，对于LT模式一样，比ET模式更加高效，只是触发一次read，而ET至少需要读取两次。对于ET模式也可以尽量一次性读取完数据，避免数据残留。
    对于写事件：能更加高效的实现发数据，避免阻塞等待，还可以实现流量控制

##### LT与ET总结

  + 读数据
    
    LT 模式下，读事件触发后，可以按需收取想要的字节数，不用把本次接收到的数据收取干净（即不用循环到 recv 或者 read 函数返回 -1，错误码为 `EWOULDBLOCK` 或 `EAGAIN`）
    
    ET 模式下，读事件必须把数据收取干净，因为你不一定有下一次机会再收取数据了，即使有机会，也可能存在上次没读完的数据没有及时处理，造成客户端响应延迟。
  + 写数据  
    
    LT 模式下，不需要写事件一定要及时移除 `EPLLOUT`，避免不必要的触发，浪费 CPU 资源；
    
    ET 模式下，写事件触发后，如果还需要下一次的写事件触发来驱动任务（例如发上次剩余的数据），你需要继续注册一次检测可写事件。

    靠事件来触发，即检测到可写事件才写数据，而不是主动的写数据。

    <font color=red> 发送数据是否需要继续注册可写事件与可写事件的移除？</font>

#### 4. 断线自动重连    

+ 对于服务器程序之间的重连可以设计成等时间间隔的定时重连，
+ 对于客户端程序要结合依次放大重连时间间隔、网络状态变化立即重连或用户主动发起重连这三个因素来设计

#### 5. 保活机制与心跳包 

心跳检测一般有两个作用：
+ 保活：不想让长时间没有数据传输的连接被防火墙关闭，那么就需要 **保活**
+ 检测死链：因网络故障导致连接没有数据传输，无论是客户端或者服务器都无法感知与对方的连接是否正常，这类连接我们一般称之为“死链”

#####  SO_KEEPLIVE 
设置 `KeepLive`选项参数 `SO_KEEPALIVE` 来保活。这个选项默认发送心跳检测数据包的时间间隔是 7200 秒（2 小时）

当然，我们可以通过继续设置 `keepalive` 相关的三个选项来改变这个时间间隔，它们分别是 `TCP_KEEPIDLE` 、 `TCP_KEEPINTVL` 和 `TCP_KEEPCNT`，示例代码如下：
```cpp
  //发送 keepalive 报文的时间间隔
  int val = 7200;
  setsockopt(fd, IPPROTO_TCP, TCP_KEEPIDLE, &val, sizeof(val));

  //两次重试报文的时间间隔
  int interval = 75;
  setsockopt(fd, IPPROTO_TCP, TCP_KEEPINTVL, &interval, sizeof(interval));
  
  // 探测几次
  int cnt = 9;
  setsockopt(fd, IPPROTO_TCP, TCP_KEEPCNT, &cnt, sizeof(cnt));
```

`TCP_KEEPIDLE` 选项设置了发送 `keepalive` 报文的时间间隔，发送时如果对端回复  `ACK` 。则本端 TCP 协议栈认为该连接依然存活，继续等 7200 秒后再发送 `keepalive` 报文；如果对端回复 `RST`，说明对端进程已经重启，本端的应用程序应该关闭该连接。

如果对端没有任何回复，则本端做重试，如果重试 9 次（ `TCP_KEEPCNT` 值）（前后重试间隔为 75 秒（ `TCP_KEEPINTVL` 值））仍然不可达，则向应用程序返回 `ETIMEOUT` （无任何应答）或 `EHOST` 错误信息

##### 应用层的心跳包机制设计

由于 `keepalive` 选项需要为每个连接中的 `socket` 开启，由于这不一定是必须的，可能会产生大量无意义的带宽浪费，且 `keepalive` 选项不能与应用层很好地交互，因此一般实际的服务开发中，还是建议读者在应用层设计自己的心跳包机制。


#### 6. 网络通信协议设计
掌握一个协议，起码是格式要掌握。get/Post 本质上是因为请求方式不同。get 是在请求的url在？后面添加请求的参数，而Post是在body里面。因此，get请求有长度限制，不安全

##### head 
+ 自定义协议
  + 定长：不能充分利用空间
  + 特定分隔符 http：如果报文里也有特定字符
  + 包头+包体
+ `tlv`格式
probuffer:
+ pb thrift：字节流的组织方式

json作为协议
+ 几个json连在一起，不容易分割
+ 是明文传输，有安全问题
+ 明文传输占用内存大