

# 生物背景+课程简介

SMMLB: Statistical Modeling and Machine Learning for Biology

## 课程简介

## 统计学

F检验 – 大数定理 – 贝叶斯推论 – 正态分布 – 方差 – 箱式图

样品选取：

- 选取多少小麦才能确保结果的准确性？
- 阿司匹林对抗癌的疗效（也有可能是其他抗癌的药物）

确定关联性

要求：

1. 基本原理
2. 基本公式
3. 科学的统计思维方法

贝叶斯推论：
$$
P(X|Y)=\frac{P(Y|X)P(X)}{P(Y)}
$$
统计学和机器学习：

- 如果你只是想从数据中找出哪类人更容易得某种疾病，机器学习可能是更好的选择。
- 如果你希望找出变量之间的关系或从数据中得出推论，选择统计模型会更好。

## 生物信息

测序

测序应用

- 产前诊断
- 癌症诊断

结构生物学

生物图像

生物现象特点：

- 变异性：个体之间差异
- 不确定性（随机性）：变异不能准确推算
- 复杂性：影响因素众多，有些是未知

基因表达数据分析

1. 差异表达基因分析
2. 基因共表达分析
3. 基因表达数据的聚类和分类
4. 基因集分析
5. 基因调控网络

基因集合分析

1. 测序一批“interesting”的基因
	1. 差异表达基因
	2. 直接做基因集分析
2. 生物学功能关联 – 某种功能是否显著
3. 计算分析方法
	1. gene ontology
	2. KEGG
	3. 超几何分布

微生物组生态数据分析

1. 物种的富集分析
2. 功能的富集分析
3. MWAS分析

## 计算科学

The art of computer programming, Donald Knuth

基因检测，比尔盖茨：sorting by reversal problem

PatternHunter, ExonHunter

Alphabet

深度学习：

1. Reinforcement Learning
2. Markov chain
3. visual recognition

机器学习：

1. 数据特征提取
2. 数据预处理
3. 训练模型
4. 测试模型
5. 模型评估改进

算法：

1. 回归 – 线性回归
2. 分类：
	1. 逻辑回归：通过Sigmoid函数将线性函数的结果映射到Sigmoid函数中，预估事件出现的概率并分类
	2. k-近邻：用距离度量最相邻的分类标签
	3. 朴素贝叶斯：$P(\omega_j|x)=\frac{p(x|\omega_j)P(\omega_j)}{p(x)}$, $p(x)=\sum_{j=1}^Np(x|\omega_j)P(\omega_j)$
	4. 决策树：构造熵值下降最快的分类树
	5. 支持向量机(SVM)：构造超平面，分类非线性数据
3. 聚类 – k-Means：计算质心，聚类无标签数据
4. 关联分析 – F-P Growth：频繁项集、关联规则、支持度、置信度
5. 降维 – 主成分分析PCA：降低数据复杂度，提高识别的精度
6. 人工神经网络：对数据之间的复杂关系进行建模，逐层抽象，逼近任意函数
7. 深度学习

## Topic

Sequence’s feature detection

- CpG island finding
- Gene finding:
	- promoter prediction
	- splicing site prediction
	- translation initial site prediction

Multiple alignment

Tree of life

- Phylogeny
- classical: morphological characters
- modern: molecular sequences
- appoaches
	- probabilistic model 概率模型
	- bootstrap 引导程序

Motif finding

Gene expression data – clustering and biomarker discovery

- microarrays

Regulatory network

- network inference
	- Bayesian network
	- Gaussian graphical model

Network analysis

- network modular (network clustering)
- network motifs

Dimension resuction

- curse of dimensionality
- techniques:
	- principal component analysis, PCA
	- singular value decomposition, SVD
	- multi-dimensional scaling, MDS
- visalization in low dimension

# 传统生物统计学

## 名词

### 概率统计

大数定理：伯努利 – 卡方检验

贝叶斯推论：利用看到的序列信息（事实），反过来推论到哪里是特定位点（剪切位点）

正态分布 – 方差 – 箱式图

t分布、t检验（学生式分布）：歌塞特，小样本检验替代大样本

F检验 – 方差分析：费歇尔 – Fisher Yates随机数字表

马尔科夫链 – mutual information

#### 基本内容

1. 

1. 

总体

样本：30

变量：

常数

参数：描述总体特征的数，通常未知

统计数：描述样本特征的数，样本观测值的已知函数

效应：

互作（连应）

变异 – 误差：

1. 随机误差/机误(random error)
2. 系统误差/错误(systematic error)

准确性

精确性

## 理论

统计分析：

1. 数据特征数的计算
2. 方差分析
3. 卡方检验
4. 回归和相关分析
	1. 孟德尔随机性
5. 协方差分析
6. 主成分分析
7. 期望最大化（EM）算法
8. 聚类
9. HMM模型（基因预测）

基本原则：重复、随机、局部控制

抽样：

1. 随机抽样：
	1. 简单随机抽样：抽签法，随机原理
	2. 分层随机抽样：区层，抽样分数，局部控制原理
	3. 整体随机抽样：群（主要变异来源明显来自区层内各区间，每一区间所占面积较小）
	4. 双重随机抽样
2. 顺序抽样（系统抽样、机械抽样）：按照既定顺序抽样，不能计算抽样误差、估计总体值
3. 典型抽样：主观选取典型群体作为样本，一般不在总体相对较小时用

统计归纳：变量分布具有集中性、离散性的特征

1. 集中性 – 平均数
	- 算数平均数：$\mu=\frac{1}{N}\sum^N_{i=1}x_i$
	- 几何平均数：$G=\sqrt[n]{x_1x_2...x_n}$
		- 适用于变量x为对数正态分布，经对数转换后成正态分布的资料
	- 调和平均数：$H=\frac{1}{\frac{1}{n}\sum\frac{1}{x}}$
		- 主要用于反映生物不同阶段的平均增长率或不同规模的平均规模
	- 中位数：$M_d$
	- 众数：$M_0$
	- 箱式图（box plot）: maximum, third quartile(Q3), median, first quartile(Q1), minimum – IQR=Q3-Q1
2. 概率分布 – 随机变量的概率分布
	- 离散型变量
		- 二项分布
		- 泊松分布
	- 连续型变量
		- 正态分布
3. 离散型 – 变异数
	- 极差
	- 方差
	- 标准差
	- 变异系数

假设推断

- 假设检验：显著性检验
- 假设推断：

变量间关系

- 函数关系（确定性）：数学表达式
- 统计关系（非确定性）
	- 因果关系（回归分析）
		- 一元回归：直线回归、曲线回归
		- 多元回归：多元线性回归、多元非线性回归
	- 相关关系（相关分析）
		- 简单相关分析：直线相关分析
		- 多元相关分析：复相关分析、偏相关分析

相关性分析：

- 直线关系
	- 正向直线关系
	- 负向直线关系
	- 直线回归方程：自变量、斜率（回归系数）、截距（回归截距）、y估计值
		- 最小二乘法
			- 点到直线的距离：$d=\sqrt{\frac{1}{k^2+1}}(y_1-(kx_1+b))$
		- 绘制散点图 – 观察趋势 – 检查异常点
		- 以自变量的取值为限：内插、外延

- 曲线关系

- 函数：对数、指数、幂函数、倒数、S形曲线

实验设计：

1. 对比设计
2. 随机区组设计
3. 裂区设计
4. 拉丁方设计
5. 正交设计

陷阱：深度学习得到的特征与样本无关

## 应用

基因差异表达

- 热图
- t-test

基因表达和性状关联性分析

基因分型

结构预测：打分函数

实际操作

生物大数据可视化

# Markov Model（马尔可夫模型）

## Markov Chain



$$
\begin{bmatrix}
P_{aa}&P_{ab}&P_{ac}\\
P_{aa}&P_{ab}&P_{ac}\\
P_{aa}&P_{ab}&P_{ac}\\
\end{bmatrix}
$$
只与上一次的吃饭地点有关

### 时齐马氏链

零阶马氏链

一阶时齐

可达 – 互通 – 不可约

常反

周期

遍历极限：

### page rank算法

网络搜索

page rank – 网页跳转访问矩阵

死网页问题 – damping factor:

MapReduce(处理过多的网页，巨大的矩阵)

## Hidden Markov Model (HMM) 理论

自己设计输入X<sub>i</sub>值，讲解，看人们穿的衣服来判断天气。

由观测值推测状态 – HMM参数较多

- 转移概率矩阵

计算方法：

- 隐过程
- 初始分布
- 转移矩阵
- 分布矩阵

识别问题 – &lambda;表示一个模型，利用Bayesian原理，猜测最好模型

- 基本（枚举复杂度2TN<sup>T</sup>）：

	- $$
		Pr(Y=y|\lambda)=\sum_{X=x}Pr(Y=y|X=x,\lambda)Pr(X=x|\lambda)=\sum_{x=(x1,...,x_T)}\pi(x_1)b_{x_1}(y_1)a_{x_1x_2}b_{x_2}(y_2)...a_{x_{T-1}x_T}b_{x_T}(y_T)
		$$

- 前传概率：

	- $\alpha_t(i)=Pr(y_1,y_2,...,x_t=i|\lambda)$，&lambda;表示一个模型
	- $\alpha_{t+1}(i)=Pr(y_1,y_2,...,y_{t+1},x{t+1}=i|\lambda)\\
		=\sum_j\alpha_t(j)a_{ji}b_i(y_{t+1})$
	- Forward Algorithm:
		- 初始 – 迭代 – 结果：$Pr(Y|\lambda)=\sum_{i=1}^N\alpha_T(i)$

- 后传概率：
	- $\beta_t(i)=Pr(y_1,y_2,...,x_t=i|\lambda)$
	- $\beta_{t}(i)=Pr(y_1,y_2,...,y_{t+1},x{t+1}=i|\lambda)\\
		=\sum_j\beta_t(j)a_{ji}b_i(y_{t+1})$
	- Forward Algorithm:
		- 初始 – 迭代 – 结果：$Pr(Y|\lambda)=\sum_{i=1}^N\beta_1(i)\pi_ib_i(y_1)$

解码问题 – Viterbi算法：

- 原则：
	- 单点最优
	- 路径最优
- 初概率
- 转移概率
- 条件概率

学习问题 – 由隐过程和过程来推算转移矩阵和分布矩阵 – 根据频率推算

- 极大似然估计
- 观测链相应的状态链已知
- 观测链相应的状态链未知 – 参数估计（EM思想）
	- EM算法（最大期望算法）：无法确定是否最优解，只是局部最优解

## HMM基因识别

CpG岛的识别

- BLOSUM62 – 状态链部分知道

gene识别

区别于底层模型 – 密码子要3个一组来考虑

geng scan – 更多考虑

药物测试

生存分析

蛋白预测

## HMM序列比对

# 进化树的概率模型

基础比较还是序列

研究热点：研究和改造进化

生物伦理：

- 可以做：老年人病入膏肓
- 不能做：新生儿
- 模糊地带：未得疾病之前就做改造

概率方法构建：二叉树

- 基于距离构建

	- UPGMA：	
		- 构建t*t矩阵
		- 寻找自小距离： 
	- Neighbor-Joining

- 基于特征构建

  - 最大简约法(Maximun Parsimony)
  	- occam’s razor method, 奥卡姆剃刀法：解释一个过程最好的理论是所需假设数目最少的一个
  	- 计算所有拓扑结构 – 代数最小的一个
  - 最大似然法(Maximum Likelihood)
  	- 似然函数
  	- 排列组合 – 54321
  	- 分子钟假设
  		- 水平基因转移 – 基因交流 – 设不成立
  	- 递归算法：
  		- ungapped alignment: 
  		- PAM矩阵

  # Motif finding的概率模型

## EM algorithm

example – 知道状态链的学习问题

EM – 永远得不到最优解

- 随机构建一棵树的结构
- MLE(cont)
- Z的设计
- 投硬币：
	- 每次投的时候知道用的是A还是B – 最大似然估计(ML)
	- 未知每次投的时候是A还是B – 最大期望法(EM)
- k-mean: 中心化，无法求环
- Hcluster(层次聚类)
- 和函数：将肉眼可看的分成不同维度
- 二维聚类：EM clustering – 每个点都有概率 – 不计算距离，计算概率
	- 高斯混合模型：两个高斯分布(正态分布)混合一起
	- 高斯函数：$f(x)=ae^{-\frac{(x-b)^2}{2c^2}}$
	- 高斯函数积分：$\int^{\infty}_{{-\infty}}e^{-ax^2}dx=\sqrt{\frac{\pi}{a}}$
	- GMM-EM

## Markov Chain Monte Carlo (MCMC)

避免给定起点对结果的影响，上山之后再下来 —— 模拟退火

### Monte Carlo

会适用于一种分布

Monte Carlo有一定的随机性

随机数：

- Linear congruence generator (LCG)：生成随机数，求模运算 – 密码学
	- 参数选择，很严谨(M)
	- Public key system (公钥) – 密码学：
		- 私钥 – collision attack

twin prime conjecture (哥德巴赫猜想) – 7000万

### MCMC

马氏链遍历性

应用：

- 生成复杂随机数 – 高维分布的随机向量
- 复杂空间上的极值 – 模拟退火：上山后下
- Gibbs Sample
- Metropolis
- Hill climbling

### Motif Finding

模体：一段序列在不同生物里面都保守 – 序列保守，长度短(模体是从序列上说的)

化学方法：DNase footprinting assay

motif特性：small & highly varible(与基因的距离多变)

最大似然估计(ML) – 只能从序列角度，要从更多的前后序列来判定

判定变量：

- 信息熵：保守型越强，熵越低
	- PWM：直接算各位点概率
	- Information – Entropy: H(x) =$2-\sum_{i=\{A,T,G,C\}}-p_i\log_2{p_i}$
	- 加入背景频率(background frequency)
		- different measure – Kullback-Leibler distance(divergence): $D_{KL}(P_{motif}||P_{bg})=\sum_{b=\{A,T,C,G\}}P_{motif}(b)\log\frac{P_{motif}(b)}{P_{bg}(b)}$
	- 保守型(以2为底的信息熵)和字母结合的图
- 互信息(Mutual information)

Assumption:

- one sequence, one motif
- has fixed length

parameter:

- $X_i$: ith sequence(观测值)
- $Z_{ij}$: motif start at position j in sequence i – 对应PWM

multinomial distribution: $Pr(X_i|Z_{ij}=1,p)= \prod_{k=1}^{j-1}p_{x_{ik},0}\prod_{k=j}^{j+W-1}p_{x_{ik},k-j+1}\prod_{k=j+W}^{L}p_{x_{ik},0}$

- motif – PSSM(:,1:n)
- background – PSSM(:,0) – $p_{x_{ik},0}$ – P(S|B)
- EM updating
	- L: 序列总长
	- W: 模体长度 

MEME Algorithm

- 不定开始位置，多判断，相比于直接固定序列位置来迭代，更加
- estimating p: 加1和4，防止结果出现0

MEME工具：

- 多起点爬山不能得到准确的最高点

Gibis采样

1. 后三条找模体 – 得矩阵 – 在第一条序列上用

# 基因表达数据分析

## 聚类分析 – Mixture model

判别问题 – 学习问题

机器学习分类：

- 监督学习 – 一开始就有分类 – 分类、回归
- 无监督学习 – 一开始没有标签，自己去找分类 – 聚类、相关性、降维
- 强化学习

聚类(cluster)工具

分等级聚类

相关性：

- 皮尔森相关性
- 欧几里得(Eud)相关性
- cosine相关性
- 傅里叶变换

KNN

连接：

- 单向连接 – 很多，但二维是一串
- 最远
- 最近
- 算中心点距离

K means

高斯混合模型 – EM算法

判断分几类(有多少个聚类点)：

- AIC
- BIC
- log-likelyhood：一个个尝试

## Classification-Lasso Based variable selection

类别预先就知道，把样本分到组里面去

### Bayesian decision rule

统计上的分类问题 – 贝叶斯的决策问题

### Fisher linear discriminant analysis

Fisher判别分析 – 组间最大，组内最小

- 过原点斜率变化 – 变化时可能跳过最大

### SVM

保证分开后，中间的空白越开越好

- 核函数 – 置换空间

拟合：

- 欠拟合
- 过拟合问题(overfitting) – 分的太好，再加一个点可能就不是那么好
	- 数据：
		- 训练数据：可以看到的数据
		- 验证数据
	- 均方误差(MSE)：$MSE=\frac{1}{n}\sum^n_{i=1}(y_i-f(x_i))^2$
	- 训练MSE减小，测试MSE变大 – 过拟合
	- 留一交叉验证
	- k折交叉检验：每次留几个

### 衡量分类器 – Measuring the accuracy of classifers

|                  | real negative     | real positive     |
| :--------------- | ----------------- | ----------------- |
| claimed positive | false positive FP | true positive TP  |
| claimed negative | true negative TN  | false negative FN |

参数：

- sensitivity (Sn): $\frac{TP}{TP+FN}$
- false positive rate (FPR): $\frac{FP}{TN+FP}$
- specificivity: 1-FPR
- correlation coefficient (CC): $\frac{TP\times TN-FP\times FN}{\sqrt{(TP+FN)(TN+FP)(TP+FP)(TN+FN)}}$
- approximate correlation (AC): $\frac{1}{2}(\frac{TP}{TP+FN}+\frac{TP}{TP+FP}+\frac{TN}{TN+FP}+\frac{TN}{TN+FN})-1$
- FDR: $\frac{N_{01}}{N_r}$
- F<sub>1</sub> score

ROC(receiver operating characteristic/relative operating characteristic)

- 分类器，Sn上升，FPR也上升，正常是对角线和偏上的二分类，这样才有用(但在实验中可能是弯曲的)
- 偏上：分离较好
- 直线：完全分不开
- 向下：全错

假设检验：

- 一型错误(type I error)：原假设正确，却拒绝了原假设 – $N_{01}$
- 二型错误(type II error)：原假设错误，没有拒绝原假设 – $N_{10}$

### Aggregating classifiers

参数不同，结合起来成为一个大的分类器 – 整合，每次换参数

随机森林(random forest, 集大成的分类器)：将判别树的结果整合，作为最终结果

- 投票

### 校正(correction)

Bonferroni method

Benjamimi method

- 通过控制FDR来决定P值的阈值
- FDR < 5%
- 造数据decoy

## gene expression classification

RNA-seq – RPKM/FPKM：数据规划

- FPKM：$FPKM=10^9\times\frac{C}{NL}$

GSEA：显著高于/显著低于所有的基因表达

## 参数选择(variable selection)

stepwise：一次去掉一个，看结果会不会更好

数据降维：

- LASSO：用正方形来切
- 岭回归(ridge regression)：用圆来切

## class comparison

# 基因网络推断

## Regulatory network

### 调控网络

可进行因果推断 – 因果性：不可反向

- 共出现 – 癌症基因与得癌症的因果性

有调控性，相关性：

- 无法通过统计方法来设计因果性：先后性
	- 只有一种方法 – 孟德尔随机化
- 实验方法简单

网络：

- 无/非尺/标度网络(scale-free network) – 连接其他点的个数分布 – 基因/社交网络
	- 正常是连接边个数正态分布，但在自然界中不常见
	- 世界上最多6个的社交圈

Clarify:

- 统计：共高或共低
- 实验：CRISPR

调控关系：震荡

### reverse engineering

逆向工程：测试一个个部件，推导整体的功能

DREAM挑战赛

### Bayesian网络

把网络变成有方向的 – 因果网络

整件事发生的概率：$P(B,E,A,C,R)=P(B)P(E)P(A|B,E)P(R|E)P(C|A)$

初级：参数学习

- 一条边 – 找到贝叶斯概率(用频率代替概率)

中级：图分解

- 找有几个概率 – 分成子网络
- 没有箭头：独立概率
- 有箭头：条件概率

高级：近似算法 – 关于图的

- 贪心算法：每次改变一个边，最后得到最可能的
	- $\Delta score=$
	- 看能不能达到局部最优
- stepwise

特级：EM算法解网络

- EM算法：
	- 通常有H隐状态
	- 数量N：
		- 独立：1
		- 条件：2<sup>n</sup>
	- training data：几个变量发生的频率
	- 参数更新
	- 结构更新

两者关系

功能网络：GO

## Gaussian Graphical Model

# 蛋白质相互作用

## 实验方法

### 物理作用

酵母双杂交 – 有人为选择因素 – 可靠性不是很高

质谱 – TAP-mass spectrometry – 组学

### 基因作用

组学的研究

很多时候说相互作用 – 从数据上说 – 同出现/共表达

数据库很多 – 其中能有实验验证的很少(10%) – 大多是预测

## P-P相互作用的预测

通过蛋白表达量来推断

证据：

- 共出现 – 时间上 – 空间上cellular location
- 结构互补配对

pfam：

- 域 – 线性排列

association：$V(D_{ij})=\frac{interacted protein pairs contain D_{ij}}{all protein pairs contain D_{ij}}$

## Network Module

difination

module detection

Bayesian approach

Markov clustering algorithm – MCL(马尔可夫聚类)

- 矩阵乘法

DB：

- STRING
- STITCH

## 蛋白质3D结构

### 结构预测

Rosetta stone

CASP(critical assessment of techniques for protein structure prediction)

- 13：DeepFold
- 14：AlphaFold – AlphaFold2
	- 中位GDT

微生物组大数据+蛋白质3D结构

- 非定向/定向方法 – 发掘未知功能基因
- 合成生物学模板
- 药物发掘/药物设计
	- 环境菌群 – 功能基因/代谢物

### AlphaFold2

数据库

### P-P相互作用

dock – 蛋白质复合物(冷冻电镜唯一的优势所在)

David Baker

Colabfold

### 蛋白质动态变化

### 蛋白质设计

ProteinMPNN

## 基因网络分析

## Network clustering

## Network Motif

## Markov random field (MRF)

# Dimension reduction(降维)

降维 – 让人能看到识别数据特征

高维 – 超平面分类 – 过拟合问题

维度爆炸 – 维度降低，准确度无法保证

## 特征选取

Feature selection – 选足够好的维度，降维后可以分很开

所有压缩问题都是特征选择的问题

很多特征相关性非常高 – 只考虑一个就有足够的代表性

### 最小冗余，最大相关 (mRMR)

### 随机森林

做决策需要几个关键特征 – 特征筛选

## 降维

映射的结果 – 判断依靠降维的方法

- 线性降维：降维时特征一样的要在一起 – 有分类的功能，但原始功能是降维
	- PCA 主成分分析 – 基因表达中主要的
		- 主成分：选取的代表原始样本的特征 – 根据样本方差最大
		- 可能不会得到肉眼可见的结果
	- LDA 线性判别分析
		- 同类接近 – 难以进一步分析，无法对同类里面做进一步分析
		- 不同类分离
	- 要素分析
		- CCA 典型相关分析 – 将数据X映射到二维平面上，用factor的Y来对这些点进行标记
			- 向外延伸的长度越长，越重要 – 将样本分的越开，越重要
		- SVD 奇异值分解 (singular value decomposition)
			- x – 基因
			- y – 样本
			- 样本排序 – 将基因表达信息聚类
- 非线性降维
	- MDS 多维尺度分析
		- 构造低维空间的内积矩阵 – 低维矩阵中两点距离和高维中一样
		- t-SNE – 单细胞表达
- LASSO
	- 核函数 kernel function – SVM

# 深度学习的应用

监督学习

- 分类
	- 简单贝叶斯
	- SVM
- 神经网络
	- 输入层
	- 中间 多层神经网络

无监督学习

- 聚类

## 概貌

机器学习过程：训练 – 测试 – 模型(一个映射函数)

- 三要素：因为机器学习要得到模型来预测未知的问题，可以看到机器学习合传统优化问题有区别
	- 模型：线性/非线性
	- 学习准则：期望风险
	- 优化：梯度下降 – 收敛到局部最优
- 类型：
	- 训练样本
	- 优化目标
	- 学习准则

深度学习：训练层数变得更多

- 层数 – 分元素矩阵变大 – 组合找到特征 – 结合
- 应用：图像领域、语音识别、视频
- 对抗学习
- 神经网络：层次网络结构 – 神经元(输入和输出)
	- 逐层优化，逐层初始化

迁移学习 – 基于深度学习 – 将猫狗的识别模型迁移到人身上

## 基本方法

自然对数

logistic激活函数，sigmoid

逻辑回归：

- 学习效率 – 每次调整的角度

神经网络：

- 输入层
- 隐藏层 – 深度学习多隐藏层 – sigmoid函数
	- 残差反向来传 – 神经网络学习：反向传播
	- 传递之间
		- 卷积(convolution)：把一个大的矩阵变成小的矩阵 – 重叠
			- 特征 – 左小右大，上下相同
			- 整体上特性的一致
		- 驰化(pooling) – 不重叠
			- 最大值驰化
- 输出层

人工神经网络(ANN)

卷积神经网络(CNN)

对抗神经网络(GAN)

强化学习

# 生物大数据挖掘的深度学习

分类 – 有监督

聚类 – 无监督

强化学习 – 有奖赏的

one-hot

对高保守序列 – 可以用强化学习来找特征

- HMM
- BLAST

建模 – 提取特征 – 建立网络